{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1316645a-53a0-4abb-a794-7d39fec62627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 14:30:58.666879: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-17 14:30:59.213144: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-17 14:31:03.250892: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-17 14:31:03.275784: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-17 14:31:07.219403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder data shapes: (81309, 10, 15) (20328, 10, 15)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 15)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                20480     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " repeat_vector (RepeatVecto  (None, 10, 32)            0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 10, 64)            24832     \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 10, 15)            975       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48367 (188.93 KB)\n",
      "Trainable params: 48367 (188.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "636/636 [==============================] - 31s 30ms/step - loss: 0.3980 - val_loss: 1.5247\n",
      "Epoch 2/10\n",
      "636/636 [==============================] - 17s 26ms/step - loss: 0.2403 - val_loss: 1.5248\n",
      "Epoch 3/10\n",
      "636/636 [==============================] - 19s 30ms/step - loss: 0.1902 - val_loss: 1.5353\n",
      "Epoch 4/10\n",
      "636/636 [==============================] - 17s 27ms/step - loss: 0.1693 - val_loss: 1.5362\n",
      "Epoch 5/10\n",
      "636/636 [==============================] - 19s 30ms/step - loss: 0.1541 - val_loss: 1.5454\n",
      "Epoch 6/10\n",
      "636/636 [==============================] - 17s 27ms/step - loss: 0.1424 - val_loss: 1.5663\n",
      "Epoch 7/10\n",
      "636/636 [==============================] - 17s 27ms/step - loss: 0.1317 - val_loss: 1.5783\n",
      "Epoch 8/10\n",
      "636/636 [==============================] - 17s 27ms/step - loss: 0.1225 - val_loss: 1.5828\n",
      "Epoch 9/10\n",
      "636/636 [==============================] - 21s 33ms/step - loss: 0.1145 - val_loss: 1.5865\n",
      "Epoch 10/10\n",
      "636/636 [==============================] - 18s 28ms/step - loss: 0.1075 - val_loss: 1.5983\n",
      "2541/2541 [==============================] - 18s 6ms/step\n",
      "Threshold: 0.863598458468914\n",
      "636/636 [==============================] - 4s 7ms/step\n",
      "Clean CM:\n",
      " [[ 5077     4]\n",
      " [  104 15143]]\n",
      "Saved: cm_clean_autoencoder.png\n",
      "636/636 [==============================] - 4s 6ms/step\n",
      "Adv CM:\n",
      " [[ 5077     4]\n",
      " [  102 15145]]\n",
      "Saved: cm_adv_autoencoder.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "# --- Load & preprocess ---\n",
    "file_path = \"data/Phasor Measurement Unit Data - Labeled/PMU_data.xlsx\"\n",
    "df = pd.read_excel(file_path).drop(columns=['Unnamed: 0'])\n",
    "X = df.drop(columns=['Class Labels']).values\n",
    "y = df['Class Labels'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Create sequences\n",
    "window = 10\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(len(X_scaled) - window):\n",
    "    X_seq.append(X_scaled[i:i + window])\n",
    "    y_seq.append(y[i + window])\n",
    "X_seq = np.array(X_seq, dtype=np.float32)\n",
    "y_seq = np.array(y_seq, dtype=np.int64)\n",
    "\n",
    "# Split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "print(\"Autoencoder data shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# --- Build LSTM Autoencoder ---\n",
    "timesteps = X_train.shape[1]\n",
    "features = X_train.shape[2]\n",
    "\n",
    "inputs = Input(shape=(timesteps, features))\n",
    "encoded = LSTM(64, activation='tanh')(inputs)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(features))(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "# --- Train ---\n",
    "autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    validation_data=(X_test, X_test),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# --- Threshold ---\n",
    "recon_train = autoencoder.predict(X_train)\n",
    "train_mse = np.mean(np.mean((recon_train - X_train)**2, axis=2), axis=1)\n",
    "threshold = train_mse.mean() + 3 * train_mse.std()\n",
    "print(f\"Threshold: {threshold}\")\n",
    "\n",
    "# --- Clean Test Evaluation ---\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "test_mse = np.mean(np.mean((recon_test - X_test)**2, axis=2), axis=1)\n",
    "y_pred_clean = (test_mse > threshold).astype(int)\n",
    "\n",
    "cm_clean = confusion_matrix(y_test, y_pred_clean)\n",
    "print(\"Clean CM:\\n\", cm_clean)\n",
    "\n",
    "# --- Save CLEAN confusion matrix figure ---\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_clean, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix – Autoencoder (Clean)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"cm_clean_autoencoder.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: cm_clean_autoencoder.png\")\n",
    "\n",
    "# --- Adversarial attack ---\n",
    "epsilon = 0.05\n",
    "X_test_adv = X_test + epsilon * np.sign(np.random.randn(*X_test.shape))\n",
    "\n",
    "recon_test_adv = autoencoder.predict(X_test_adv)\n",
    "test_adv_mse = np.mean(np.mean((recon_test_adv - X_test_adv)**2, axis=2), axis=1)\n",
    "y_pred_adv = (test_adv_mse > threshold).astype(int)\n",
    "\n",
    "cm_adv = confusion_matrix(y_test, y_pred_adv)\n",
    "print(\"Adv CM:\\n\", cm_adv)\n",
    "\n",
    "# --- Save ADV confusion matrix figure ---\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_adv, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
    "plt.title(\"Confusion Matrix – Autoencoder (Adversarial)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"cm_adv_autoencoder.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: cm_adv_autoencoder.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05838f05-9bd7-49e4-824e-a6865f058d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
