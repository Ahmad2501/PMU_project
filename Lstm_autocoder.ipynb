{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316645a-53a0-4abb-a794-7d39fec62627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder data shapes: (81309, 10, 15) (20328, 10, 15)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 15)]          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                20480     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " repeat_vector_1 (RepeatVec  (None, 10, 32)            0         \n",
      " tor)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 10, 64)            24832     \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, 10, 15)            975       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48367 (188.93 KB)\n",
      "Trainable params: 48367 (188.93 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "636/636 [==============================] - 26s 36ms/step - loss: 0.3943 - val_loss: 1.5715\n",
      "Epoch 2/10\n",
      "636/636 [==============================] - 19s 29ms/step - loss: 0.2440 - val_loss: 1.5460\n",
      "Epoch 3/10\n",
      "636/636 [==============================] - 17s 26ms/step - loss: 0.1919 - val_loss: 1.5401\n",
      "Epoch 4/10\n",
      "636/636 [==============================] - 16s 26ms/step - loss: 0.1677 - val_loss: 1.5527\n",
      "Epoch 5/10\n",
      "636/636 [==============================] - 17s 26ms/step - loss: 0.1521 - val_loss: 1.5669\n",
      "Epoch 6/10\n",
      "636/636 [==============================] - 17s 27ms/step - loss: 0.1382 - val_loss: 1.5827\n",
      "Epoch 7/10\n",
      "636/636 [==============================] - 18s 29ms/step - loss: 0.1259 - val_loss: 1.5880\n",
      "Epoch 8/10\n",
      "636/636 [==============================] - 18s 28ms/step - loss: 0.1154 - val_loss: 1.5987\n",
      "Epoch 9/10\n",
      "636/636 [==============================] - 18s 28ms/step - loss: 0.1075 - val_loss: 1.6052\n",
      "Epoch 10/10\n",
      "636/636 [==============================] - 20s 31ms/step - loss: 0.1010 - val_loss: 1.6158\n",
      "2541/2541 [==============================] - 17s 6ms/step\n",
      "Threshold: 0.8617030084133148\n",
      "636/636 [==============================] - 4s 7ms/step\n",
      "Clean CM:\n",
      " [[ 5073     8]\n",
      " [   83 15164]]\n",
      "Saved: cm_clean_autoencoder.png\n",
      "636/636 [==============================] - 4s 6ms/step\n",
      "Adv CM:\n",
      " [[ 5073     8]\n",
      " [   70 15177]]\n",
      "Saved: cm_adv_autoencoder.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "#  Load and preprocess \n",
    "file_path = \"data/Phasor Measurement Unit Data - Labeled/PMU_data.xlsx\"\n",
    "df = pd.read_excel(file_path).drop(columns=['Unnamed: 0'])\n",
    "X = df.drop(columns=['Class Labels']).values\n",
    "y = df['Class Labels'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Create sequences\n",
    "window = 10\n",
    "X_seq, y_seq = [], []\n",
    "for i in range(len(X_scaled) - window):\n",
    "    X_seq.append(X_scaled[i:i + window])\n",
    "    y_seq.append(y[i + window])\n",
    "X_seq = np.array(X_seq, dtype=np.float32)\n",
    "y_seq = np.array(y_seq, dtype=np.int64)\n",
    "\n",
    "# Split\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "print(\"Autoencoder data shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# Build LSTM autoencoder \n",
    "timesteps = X_train.shape[1]\n",
    "features = X_train.shape[2]\n",
    "\n",
    "inputs = Input(shape=(timesteps, features))\n",
    "encoded = LSTM(64, activation='tanh')(inputs)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "decoded = LSTM(64, activation='tanh', return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(features))(decoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train \n",
    "autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    validation_data=(X_test, X_test),\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Threshold \n",
    "recon_train = autoencoder.predict(X_train)\n",
    "train_mse = np.mean(np.mean((recon_train - X_train)**2, axis=2), axis=1)\n",
    "threshold = train_mse.mean() + 3 * train_mse.std()\n",
    "print(f\"Threshold: {threshold}\")\n",
    "\n",
    "# clean test evaluation\n",
    "recon_test = autoencoder.predict(X_test)\n",
    "test_mse = np.mean(np.mean((recon_test - X_test)**2, axis=2), axis=1)\n",
    "y_pred_clean = (test_mse > threshold).astype(int)\n",
    "\n",
    "cm_clean = confusion_matrix(y_test, y_pred_clean)\n",
    "print(\"Clean CM:\\n\", cm_clean)\n",
    "\n",
    "# Save CLEAN confusion matrix \n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_clean, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix â€“ Autoencoder (Clean)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"cm_clean_autoencoder.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: cm_clean_autoencoder.png\")\n",
    "\n",
    "# Adversarial attack\n",
    "epsilon = 0.05\n",
    "X_test_adv = X_test + epsilon * np.sign(np.random.randn(*X_test.shape))\n",
    "\n",
    "recon_test_adv = autoencoder.predict(X_test_adv)\n",
    "test_adv_mse = np.mean(np.mean((recon_test_adv - X_test_adv)**2, axis=2), axis=1)\n",
    "y_pred_adv = (test_adv_mse > threshold).astype(int)\n",
    "\n",
    "cm_adv = confusion_matrix(y_test, y_pred_adv)\n",
    "print(\"Adv CM:\\n\", cm_adv)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm_adv, annot=True, fmt=\"d\", cmap=\"Reds\")\n",
    "plt.title(\"Confusion Matrix  Autoencoder (Adversarial)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"cm_adv_autoencoder.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved: cm_adv_autoencoder.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05838f05-9bd7-49e4-824e-a6865f058d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
